{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce24565-99c8-4813-b8e6-3031fae2ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 19 20:18:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   31C    P8    19W / 300W |      0MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e822882c-a322-41b2-80dc-0c43f6f49c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"HF_HOME\"] =\"/fs/nexus-scratch/xhnotic/.cache/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d012f2-548b-4f30-bc35-299e22f33eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528deba2-e6ec-4643-bd48-48b38ba4ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfshomes/xhnotic/miniconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f37f16-3a18-40a4-8520-01218a416eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:17<00:00, 25.67s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"eachadea/vicuna-13b-1.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"eachadea/vicuna-13b-1.1\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdede813-e5b6-4290-8752-60854094e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input content, output paraphrased content\n",
    "def paraphrase(content):\n",
    "\n",
    "    instruction =\"USER:\\n\" + \"Paraphrase the following sentences:\"\n",
    "    input_text =  instruction + content\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    output = model.generate(input_ids, max_length=1024, do_sample=True, temperature=1, output_scores=True, return_dict_in_generate=True)\n",
    "    response = tokenizer.decode(output[\"sequences\"][0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the substring after \"ASSISTANT:\"\n",
    "    index = response.find(\"ASSISTANT:\")\n",
    "    if index != -1:\n",
    "        result = response[index + len(\"ASSISTANT:\"):].strip()\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f3964f9-08a5-4e79-b5e3-68c14f2c8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input a long string, returns grouped paragraph\n",
    "def group_string(strings, group_size=10):\n",
    "    \n",
    "    grouped_strings = []\n",
    "    tokenized_strings = sent_tokenize(strings)\n",
    "    for i in range(0, len(tokenized_strings), group_size):\n",
    "        group = ''.join(tokenized_strings[i:i+group_size])\n",
    "        grouped_strings.append(group)\n",
    "        \n",
    "    return grouped_strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665d986-9900-46e2-888c-73cd5afd63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_2_paraphrased(article, group_size=10):\n",
    "    string_list = group_string(article, group_size=10)\n",
    "    paraphrased_list = []\n",
    "    for i in range(len(string_list)):\n",
    "        paraphrased_string = paraphrase(string_list[i])\n",
    "        paraphrased_list.append(paraphrased_string)\n",
    "        \n",
    "    returnparaphrased_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
